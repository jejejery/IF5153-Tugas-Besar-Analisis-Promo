{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4JlQavmceb2u",
        "outputId": "d4bd566b-a261-48cf-98c6-32a9e0d1b6fa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install nltk"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Umd46aFerwB",
        "outputId": "87c930d8-3764-4fea-a360-2d83e1d96d20"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.9.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk) (2024.9.11)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk) (4.66.6)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import requests"
      ],
      "metadata": {
        "id": "pb0xgJYsfUtC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "PATH = '/content/drive/MyDrive/NLP_dataset/annotations.json'\n",
        "url = \"https://raw.githubusercontent.com/jejejery/IF5153-Tugas-Besar-Analisis-Promo/main/data/data_ner_annotations.json\"\n",
        "# read json\n",
        "# with open(PATH) as f:\n",
        "#   data = json.load(f)\n",
        "#read json from url\n",
        "\n",
        "response = requests.get(url)\n",
        "data = response.json()\n",
        "\n",
        "data"
      ],
      "metadata": {
        "id": "Bdv3g_IcfZJG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "# Shuffle data untuk memastikan distribusi acak\n",
        "random.seed(42)  # Untuk reprodusibilitas\n",
        "random.shuffle(data['annotations'])"
      ],
      "metadata": {
        "id": "hKdWUbo4fnTg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "split_ratio = 0.85  # 85% train, 15% test\n",
        "data_annotations = data['annotations']\n",
        "train_size = int(len(data_annotations) * split_ratio)\n",
        "train_data = data_annotations[:train_size]\n",
        "test_data = data_annotations[train_size:]"
      ],
      "metadata": {
        "id": "y1YUhAl0hZb0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "from spacy.training.example import Example\n",
        "from spacy.util import minibatch, compounding\n",
        "\n",
        "\n",
        "nlp = spacy.blank(\"id\")\n",
        "nlp.add_pipe('ner')\n",
        "nlp.begin_training()\n",
        "\n",
        "ner=nlp.get_pipe(\"ner\")\n",
        "\n",
        "pipe_exceptions = [\"ner\", \"trf_wordpiecer\", \"trf_tok2vec\"]\n",
        "\n",
        "unaffected_pipes = [pipe for pipe in nlp.pipe_names if pipe not in pipe_exceptions]\n",
        "\n",
        "# Add label to model NER\n",
        "for _, annotations in train_data:\n",
        "    for ent in annotations[\"entities\"]:\n",
        "        ner.add_label(ent[2])\n",
        "\n",
        "optimizer = nlp.begin_training()\n",
        "\n",
        "for epoch in range(30):\n",
        "    random.shuffle(train_data)\n",
        "    losses = {}\n",
        "    batches = minibatch(train_data, size=compounding(4.0, 32.0, 1.001))\n",
        "    for batch in batches:\n",
        "        examples = [Example.from_dict(nlp.make_doc(text), ann) for text, ann in batch]\n",
        "        nlp.update(examples, drop=0.3, losses=losses)\n",
        "    print(f\"Losses at epoch {epoch}: {losses}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ybqJC9zjiQVC",
        "outputId": "5a7f7c05-1263-458f-9754-9c31a6f53d90"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \" Cashback 75% dengan Allo Bank bikin top up makin ...\" with entities \"[[1, 13, 'PROMO'], [21, 30, 'PLATFORM'], [86, 92, ...\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"@RacunBelanja Promo transportasi pelantikan presid...\" with entities \"[[1, 13, 'PLATFORM'], [33, 73, 'EVENT'], [74, 89, ...\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"SPORT STATION lagI ada banyak promo nihh diskon sa...\" with entities \"[[0, 13, 'PLATFORM'], [41, 65, 'PROMO'], [77, 91, ...\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"@tokopedia Promo 10x Flash Sale serba 10 ribu. Dij...\" with entities \"[[1, 10, 'PLATFORM'], [11, 46, 'PROMO'], [55, 79, ...\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"@tokopedia Jam tokopedia happy hour yang selalu sa...\" with entities \"[[1, 10, 'PLATFORM'], [15, 35, 'EVENT'], [75, 84, ...\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \" @tokopedia yang paling ku tungguinnn ° ° Diskon 3...\" with entities \"[[2, 11, 'PLATFORM'], [42, 52, 'PROMO'], [57, 86, ...\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"@tokopedia jam 19-20 WIB. Paling ditunggu promo di...\" with entities \"[[1, 10, 'PLATFORM'], [11, 25, 'TIME'], [48, 63, '...\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"PROMO 10K SAMPAI 100% Rekber/langsung Langsung dm!...\" with entities \"[[0, 21, 'PROMO'], [82, 86, 'PLATFORM']]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"Jalan-Jalan Hemat di Jakarta hanya dengan Rp 1! Pr...\" with entities \"[[21, 28, 'LOCATION'], [48, 90, 'PROMO'], [97, 116...\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"Wts Voucer Goride Diskon 7 5k ready banyak bisa ce...\" with entities \"[[4, 10, 'PRODUCT'], [11, 17, 'PRODUCT'], [18, 29,...\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"@tokopedia jam 19.00-20.00 WIB. Paling ditunggu tu...\" with entities \"[[1, 10, 'PLATFORM'], [11, 31, 'TIME'], [52, 74, '...\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"@tokopedia jam 19.00-20.00 WIB. Paling ditunggu tu...\" with entities \"[[1, 10, 'PLATFORM'], [11, 31, 'TIME'], [58, 74, '...\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"Lengah dikit UTBK tinggal 193 hari lagi Gass belaj...\" with entities \"[[13, 17, 'EVENT'], [26, 34, 'TIME'], [58, 66, 'TI...\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"RDAFFAYOBAHAGIA5 Kode promo reddoors yang ingin st...\" with entities \"[[0, 27, 'PROMO'], [28, 36, 'PLATFORM'], [71, 76, ...\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"Atau sarapan sop daging. Masih ada promo porkee di...\" with entities \"[[52, 61, 'PLATFORM'], [62, 77, 'PROMO'], [78, 93,...\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"Mau makan di resto banyak promo? Sini sini! Ada pr...\" with entities \"[[54, 65, 'EVENT'], [72, 82, 'PLATFORM'], [101, 12...\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \" Promo Chatime GrabFood Super Brand Week! Dapatkan...\" with entities \"[[7, 14, 'PLATFORM'], [15, 23, 'PRODUCT'], [24, 40...\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"Promo diamond ML 278 67.500 berlaku kelipatan Wdp ...\" with entities \"[[0, 27, 'PROMO'], [134, 138, 'PLATFORM']]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"Hal-hal yang bikin Paps good mood seharian setuju ...\" with entities \"[[135, 141, 'PRODUCT'], [147, 162, 'PRODUCT']]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"HP GRATIS DI HARI MINGGU CUMA DI JAM 19.00-20.00 A...\" with entities \"[[0, 9, 'PROMO'], [13, 24, 'TIME'], [33, 48, 'TIME...\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"Diskon Voucher Potongan harga Pesawat Maskapai Tra...\" with entities \"[[0, 67, 'PROMO'], [134, 137, 'PLATFORM'], [212, 2...\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"@tokopedia Tokopedia Happy Hour ada di 19.00-20.00...\" with entities \"[[1, 10, 'PLATFORM'], [11, 31, 'EVENT'], [39, 54, ...\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"@tokopedia Voucher diskon 30% setiap pukul 19.00 W...\" with entities \"[[1, 10, 'PLATFORM'], [11, 29, 'PROMO'], [37, 52, ...\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"@tokopedia Tokopedia Happy Hour di jam 19.00-20.00...\" with entities \"[[1, 10, 'PLATFORM'], [11, 31, 'EVENT'], [35, 50, ...\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"@tokopedia Tokopedia Happy Hour hanya 1 Jam 19.00-...\" with entities \"[[1, 10, 'PLATFORM'], [11, 31, 'EVENT'], [38, 43, ...\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"@tokopedia KAMU NANYA PROMO APA YG AKU TUNGGU TAPI...\" with entities \"[[1, 10, 'PLATFORM'], [102, 122, 'EVENT'], [142, 1...\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"HARI MINGGU DAPET HP GRATIS CUMA DI JAM 19.00-20.0...\" with entities \"[[0, 11, 'TIME'], [36, 51, 'TIME'], [77, 86, 'PLAT...\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"@tokopedia jam 19-20 WIB. Paling ditunggu promo di...\" with entities \"[[1, 10, 'PLATFORM'], [11, 25, 'TIME'], [42, 63, '...\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"@tokopedia Tokopedia Hour dimulai pada jam 19.00 W...\" with entities \"[[1, 10, 'PLATFORM'], [11, 25, 'EVENT'], [39, 52, ...\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"Jangan biarkan poin MyPertamina kamu sia-sia! Tuka...\" with entities \"[[20, 31, 'PLATFORM'], [59, 110, 'PROMO'], [177, 1...\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"Promo Cashback OVO Points di PLN Mobile! Dapatkan ...\" with entities \"[[0, 25, 'PROMO'], [29, 39, 'PRODUCT'], [50, 61, '...\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"@tokopedia Di jam 19.00-20.00 WIB setiap harinya d...\" with entities \"[[1, 10, 'PLATFORM'], [14, 33, 'TIME'], [34, 48, '...\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"@tokopedia Mulai dari jam 19.00 -20.00 promo disko...\" with entities \"[[1, 10, 'PLATFORM'], [22, 38, 'TIME'], [39, 56, '...\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"Beli paket internet &amp; pulsa Telkomsel bisa dap...\" with entities \"[[5, 19, 'PRODUCT'], [26, 41, 'PRODUCT'], [54, 68,...\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"@tokopedia Get your hands on the best discounts in...\" with entities \"[[1, 10, 'PLATFORM'], [66, 75, 'PLATFORM'], [88, 9...\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"@tokopedia Mulainya jam 19.00 WIB kalau promo nung...\" with entities \"[[1, 10, 'PLATFORM'], [20, 33, 'TIME'], [55, 93, '...\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"Abis belanja pertama dapet lagi diskon 15RB buat p...\" with entities \"[[32, 43, 'PROMO'], [49, 62, 'PRODUCT'], [140, 149...\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"@tokopedia Tokopedia happy hour dari jam 19.00 -20...\" with entities \"[[1, 10, 'PLATFORM'], [11, 31, 'EVENT'], [37, 53, ...\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"@tokopedia Promo guncang 10.10 dijamin dapet Promo...\" with entities \"[[1, 10, 'PLATFORM'], [17, 30, 'EVENT'], [45, 76, ...\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"Promo Superbank hadir kembali Cukup Tahan Saldo 50...\" with entities \"[[6, 15, 'PLATFORM'], [64, 73, 'PLATFORM'], [86, 9...\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"PROMO DM ML VIA ID 4830dm ml 810k 2010 dm ml 405k ...\" with entities \"[[0, 33, 'PROMO'], [34, 49, 'PROMO'], [94, 98, 'PL...\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"Rayakan Promo Ranch Market 26th Anniversary Discou...\" with entities \"[[14, 43, 'EVENT'], [60, 75, 'PROMO'], [126, 145, ...\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"braw! haloww sender mau bagi² promo gojekk hihii K...\" with entities \"[[36, 42, 'PLATFORM'], [60, 65, 'PLATFORM'], [66, ...\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"@tokopedia hari gini masih nanyain promo di tokope...\" with entities \"[[1, 10, 'PLATFORM'], [44, 53, 'PLATFORM'], [123, ...\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \" @mwanual Haloo yuk jajan layout di @parkyoriii ad...\" with entities \"[[37, 47, 'LOCATION'], [70, 91, 'TIME'], [94, 101,...\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"Info Promo Grab Food Jangan lupa masih ada diskon ...\" with entities \"[[11, 20, 'PRODUCT'], [43, 63, 'PROMO']]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"@tokopedia jam 19.00 voucher yang ditunggu jelas p...\" with entities \"[[1, 10, 'PLATFORM'], [11, 20, 'TIME'], [55, 64, '...\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"Dapatkan berbagai produk kategori MAKANAN &amp; MI...\" with entities \"[[70, 79, 'PLATFORM'], [95, 115, 'TIME'], [176, 18...\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"@tokopedia Jam 19.00-20.00 dan Promo yang paling d...\" with entities \"[[1, 10, 'PLATFORM'], [11, 26, 'TIME'], [68, 88, '...\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Losses at epoch 0: {'ner': 3447.8441379614205}\n",
            "Losses at epoch 1: {'ner': 2217.024534631687}\n",
            "Losses at epoch 2: {'ner': 1920.492260533483}\n",
            "Losses at epoch 3: {'ner': 1708.3351862458146}\n",
            "Losses at epoch 4: {'ner': 1486.6851791677757}\n",
            "Losses at epoch 5: {'ner': 1395.1171281634752}\n",
            "Losses at epoch 6: {'ner': 1324.8743170393188}\n",
            "Losses at epoch 7: {'ner': 1184.943350036738}\n",
            "Losses at epoch 8: {'ner': 1062.1979066168237}\n",
            "Losses at epoch 9: {'ner': 1014.2302659002289}\n",
            "Losses at epoch 10: {'ner': 1084.603600123131}\n",
            "Losses at epoch 11: {'ner': 943.9337054617233}\n",
            "Losses at epoch 12: {'ner': 799.8786049815302}\n",
            "Losses at epoch 13: {'ner': 799.3880852931787}\n",
            "Losses at epoch 14: {'ner': 745.3660398243195}\n",
            "Losses at epoch 15: {'ner': 759.1729677018767}\n",
            "Losses at epoch 16: {'ner': 684.3305327237655}\n",
            "Losses at epoch 17: {'ner': 642.8751814068104}\n",
            "Losses at epoch 18: {'ner': 640.5230058419003}\n",
            "Losses at epoch 19: {'ner': 603.3670813211212}\n",
            "Losses at epoch 20: {'ner': 538.1850413071985}\n",
            "Losses at epoch 21: {'ner': 535.9093404604401}\n",
            "Losses at epoch 22: {'ner': 548.8897724958638}\n",
            "Losses at epoch 23: {'ner': 488.1315278260093}\n",
            "Losses at epoch 24: {'ner': 449.48276393791514}\n",
            "Losses at epoch 25: {'ner': 433.5876338707843}\n",
            "Losses at epoch 26: {'ner': 457.226106604476}\n",
            "Losses at epoch 27: {'ner': 462.90912163480584}\n",
            "Losses at epoch 28: {'ner': 416.17838941455955}\n",
            "Losses at epoch 29: {'ner': 388.4688831665672}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#export the model\n",
        "output_dir = \"/content/drive/MyDrive/TUGAS BESAR NLP/MODEL/Promo-NER/\"\n",
        "nlp.to_disk(output_dir)"
      ],
      "metadata": {
        "id": "AoU4yX6SgqKW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import Counter\n",
        "\n",
        "def evaluate_ner(actual_entities, predicted_entities):\n",
        "    tp = 0  # True Positives\n",
        "    fp = 0  # False Positives\n",
        "    fn = 0  # False Negatives\n",
        "\n",
        "    # Iterasi untuk mencocokkan actual dan predicted\n",
        "    for actual_text, actual_label in actual_entities:\n",
        "        match_found = False\n",
        "        for predicted_text, predicted_label in predicted_entities:\n",
        "            if actual_label == predicted_label:  # Cek label cocok\n",
        "                # Cek subset match\n",
        "                if predicted_text in actual_text or actual_text in predicted_text:\n",
        "                    tp += 1\n",
        "                    match_found = True\n",
        "                    break\n",
        "        if not match_found:\n",
        "            fn += 1  # Tidak ditemukan pasangan yang cocok untuk entitas aktual\n",
        "\n",
        "    # Hitung false positives\n",
        "    for predicted_text, predicted_label in predicted_entities:\n",
        "        match_found = False\n",
        "        for actual_text, actual_label in actual_entities:\n",
        "            if predicted_label == actual_label:  # Cek label cocok\n",
        "                # Cek subset match\n",
        "                if predicted_text in actual_text or actual_text in predicted_text:\n",
        "                    match_found = True\n",
        "                    break\n",
        "        if not match_found:\n",
        "            fp += 1  # Tidak ditemukan pasangan yang cocok untuk entitas prediksi\n",
        "\n",
        "    # Total Entities\n",
        "    total_entities = len(actual_entities) + len(predicted_entities) - tp\n",
        "\n",
        "    # Hitung metrik\n",
        "    precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
        "    recall = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
        "    f1 = (2 * precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
        "    accuracy = tp / total_entities if total_entities > 0 else 0\n",
        "\n",
        "    return {\"precision\": precision, \"recall\": recall, \"f1\": f1, \"accuracy\": accuracy}\n",
        "\n",
        "# Evaluasi data test\n",
        "overall_results = Counter()  # Untuk menghitung rata-rata\n",
        "for text, annotations in test_data:\n",
        "\n",
        "    # Parse annotations to extract actual entities\n",
        "    actual_entities = [(text[ent[0]:ent[1]], ent[2]) for ent in annotations[\"entities\"]]\n",
        "\n",
        "    # Predicted annotations\n",
        "    doc = nlp(text)  # Predict using the trained model\n",
        "    predicted_entities = [(ent.text, ent.label_) for ent in doc.ents]\n",
        "\n",
        "    # Hitung metrik untuk teks ini\n",
        "    results = evaluate_ner(actual_entities, predicted_entities)\n",
        "\n",
        "\n",
        "    # Update hasil keseluruhan\n",
        "    overall_results.update(results)\n",
        "\n",
        "# Hitung rata-rata untuk keseluruhan data test\n",
        "average_precision = overall_results[\"precision\"] / len(test_data)\n",
        "average_recall = overall_results[\"recall\"] / len(test_data)\n",
        "average_f1 = overall_results[\"f1\"] / len(test_data)\n",
        "\n",
        "print(\"Overall Performance:\")\n",
        "print(f\"Precision: {average_precision:.2f}, Recall: {average_recall:.2f}, F1: {average_f1:.2f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V84GFj-RjVay",
        "outputId": "b05b57ca-c673-4670-bf04-2cf14697e4c2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overall Performance:\n",
            "Precision: 0.74, Recall: 0.61, F1: 0.64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#export test_data to test_data_path\n",
        "#test_data is json array\n",
        "test_data_path = \"/content/drive/MyDrive/TUGAS BESAR NLP/COMBINED/test_dataset_ner.json\"\n",
        "\n",
        "with open(test_data_path, \"w\", encoding=\"utf-8\") as json_file:\n",
        "    json.dump(test_data, json_file, ensure_ascii=False, indent=4)\n",
        "\n",
        "print(f\"Data berhasil diekspor ke {test_data_path}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rv7YppfKjKss",
        "outputId": "84e2450d-8e67-4104-cf90-f07d6b707189"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data berhasil diekspor ke /content/drive/MyDrive/TUGAS BESAR NLP/COMBINED/test_dataset_ner.json\n"
          ]
        }
      ]
    }
  ]
}